{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model : Polynomial Regression (Based on CV Score)\n",
    "- CV Score:  0.9114985160662464\n",
    "- Training Score: 0.9114985160662464\n",
    "- Test Score: 0.8755530241459522 \n",
    "\n",
    "\n",
    "## Linear Regression\n",
    "- CV score:  0.9114426745730106\n",
    "- Training score: 0.9102975951657948\n",
    "- Test Score: 0.8746968378820517\n",
    "\n",
    "\n",
    "## Polynomial Regression\n",
    "- - Models used with hyperparameters : 'degree':(1,2)\n",
    "- best params {'degree': 1}\n",
    "- CV Score:  0.9114985160662464\n",
    "- Training Score: 0.9114985160662464\n",
    "- Test Score: 0.8755530241459522\n",
    "\n",
    "\n",
    "## SGD Regressor\n",
    "- Models used with hyperparameters : {learning_rate':['invscaling','adaptive'],'penalty':['l2', 'l1','elasticnet'],\n",
    "             'alpha':[0.0001,0.0005,0.001],\n",
    "             'l1_ratio':[0.15,0.20,0.40,0.50,0.60],\n",
    "             'tol':[1e-4,1e-3]\n",
    "- Best Model parameters: {'alpha': 0.0005, 'l1_ratio': 0.5, 'learning_rate': 'adaptive', 'penalty': 'elasticnet', 'tol': 0.001} \n",
    "- CV Score:  0.891594730863832\n",
    "- Training Score: 0.891594730863832\n",
    "- Test Score: 0.8308356404127091\n",
    "\n",
    "## Ridge Regressor\n",
    " - Models used with hyperparameters :'alpha':[0.001, 0.01,0.05, 0.1, 0.25,0.5,1, 10,100,150]\n",
    " - Best Model parameters: 'alpha': 100\n",
    " - CV Score:  0.8841976405377137\n",
    " - Training Score: 0.9103295889443214\n",
    " - Test Score: 0.8731529205790174\n",
    " \n",
    " \n",
    "## Lasso Regressor\n",
    " - Models used with hyperparameters :'alpha':[0.001, 0.01,0.05, 0.1, 0.25,0.5,1, 10,100,150]\n",
    " - Best Model parameters: 'alpha': 150\n",
    " - CV Score:  0.8856334588062339\n",
    " - Training Score: 0.9110302586543852\n",
    " - Test Score: 0.87806158664072\n",
    " \n",
    "## KNN Regressor\n",
    " - Models used with hyperparameters: 'weights':['uniform','distance'],'leaf_size': [5,10,20,30],'n_neighbors': [5,10,15],'p':[1,2,3]}\n",
    " - Best Model parameters: 'leaf_size': 5, 'n_neighbors': 5, 'p': 1, 'weights': 'distance'\n",
    "  - CV Score:  0.8354252209693938\n",
    " - Training Score: 0.9999955968722103\n",
    " - Test Score: 0.7898527883440282\n",
    " \n",
    "## Decision Tree Regresser\n",
    " - Models used with hyperparameters:    'criterion':['mse','friedman_mse','mae'],'splitter':['random','best'],\n",
    "    'max_depth':[20,30],'min_samples_split':[4,8,12,16],'min_samples_leaf' :[2,4,8],'max_features':['auto','sqrt']\n",
    " - Best Model parameters: {criterion': 'mse', 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 12, 'splitter': 'random'}\n",
    " - CV Score:  0.7980363024025918\n",
    " - Training Score: 0.8771368435976774\n",
    " - Test Score: 0.8033735005070397\n",
    " \n",
    "## SVM Regressor\n",
    " - Models used with hyperparameters: kernel':['linear','poly','rbf','sigmoid'],'degree':[3,4,5],'gamma':['auto','scale'],'coef0':[2.0,4.0,10.0,15.0]\n",
    " - Best Model parameters: {'coef0': 10.0, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
    " - CV Score:  0.9004499345276106\n",
    " - Training Score: 0.9534721185647854\n",
    " - Test Score: 0.8741830276841772\n",
    " \n",
    " \n",
    "## Multiple Models with One GridSearch\n",
    " \n",
    " - Models used with hyperparameters:{ 'regressor' :[LinearRegression(), Ridge() , Lasso()]}\n",
    " - Best Model parameters: 'regressor': Lasso(alpha=200, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "      normalize=False, positive=False, precompute=False, random_state=None,\n",
    "      selection='cyclic', tol=0.0001, warm_start=False), 'alpha': 200}\n",
    "- CV Score:  0.83\n",
    "- Train Score: 0.981937071382834\n",
    "- Test Score: 0.8740776530267179   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:32:49.555666Z",
     "start_time": "2020-03-09T07:32:49.545638Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:32:50.854852Z",
     "start_time": "2020-03-09T07:32:50.812739Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# your code here\n",
    "data = pd.read_csv('/Users/tapas/Downloads/Oil/houseprice.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:32:51.725905Z",
     "start_time": "2020-03-09T07:32:51.719889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of House Id labels:  1460\n",
      "Number of Houses in the Dataset:  1460\n"
     ]
    }
   ],
   "source": [
    "# we have an Id variable, that we should not use for predictions:\n",
    "\n",
    "print('Number of House Id labels: ', len(data.Id.unique()))\n",
    "print('Number of Houses in the Dataset: ', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:32:53.140553Z",
     "start_time": "2020-03-09T07:32:53.135036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43 categorical variables\n"
     ]
    }
   ],
   "source": [
    "# find categorical variables- hint data type = 'O'\n",
    "\n",
    "categorical = [var for var in data.columns if data[var].dtype=='O']\n",
    "\n",
    "print(f'There are {len(categorical)} categorical variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find temporal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:32:54.328164Z",
     "start_time": "2020-03-09T07:32:54.321146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of the numerical variables first= Hint data type != O\n",
    "numerical = [var for var in data.columns if data[var].dtype!='O']\n",
    "\n",
    "# list of variables that contain year information= Hint variable namme has Yr or \n",
    "year_vars = [var for var in numerical if 'Yr' in var or 'Year' in var]\n",
    "\n",
    "year_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find discrete variables\n",
    "\n",
    "To identify discrete variables- numerical variables with less than 20 unique values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:32:55.849304Z",
     "start_time": "2020-03-09T07:32:55.835765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14 discrete variables\n"
     ]
    }
   ],
   "source": [
    "# let's visualise the values of the discrete variables\n",
    "discrete = [var for var in numerical if len(data[var].unique()) < 20 and var not in year_vars]\n",
    "\n",
    "print(f'There are {len(discrete)} discrete variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:32:57.274949Z",
     "start_time": "2020-03-09T07:32:57.268932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 38 numerical and continuous variables\n"
     ]
    }
   ],
   "source": [
    "# find continuous variables- hint numerical variables not in discrete and  year_years \n",
    "# Also remove the Id variable and the target variable SalePrice\n",
    "# which are both also numerical\n",
    "\n",
    "continuous = [var for var in numerical if var not in discrete and var not in [\n",
    "    'Id', 'SalePrice'] and var not in year_vars]\n",
    "\n",
    "print('There are {} numerical and continuous variables'.format(len(numerical)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:32:58.666697Z",
     "start_time": "2020-03-09T07:32:58.651653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1314, 79), (146, 79))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's separate into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['Id', 'SalePrice'], axis=1),\n",
    "                                                    data['SalePrice'],\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will move on and engineer the features of this dataset. The most important part for this course.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Craete New Variables\n",
    "\n",
    "Replace 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt  with time elapsed since YrSold\n",
    "So YearBuilt = YrSold-YearBuilt. \n",
    "\n",
    "Similarly transform 'YearRemodAdd', 'GarageYrBlt.\n",
    "After making transformation drop YrSold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:00.776674Z",
     "start_time": "2020-03-09T07:33:00.771663Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to calculate elapsed time\n",
    "\n",
    "def elapsed_years(df, var):\n",
    "    # capture difference between year variable and\n",
    "    # year the house was sold\n",
    "    \n",
    "    df[var] = df['YrSold'] - df[var]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:02.547542Z",
     "start_time": "2020-03-09T07:33:02.540522Z"
    }
   },
   "outputs": [],
   "source": [
    "for var in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']:\n",
    "    X_train = elapsed_years(X_train, var)\n",
    "    X_test = elapsed_years(X_test, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:03.567722Z",
     "start_time": "2020-03-09T07:33:03.559698Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop YrSold\n",
    "X_train.drop('YrSold', axis=1, inplace=True)\n",
    "X_test.drop('YrSold', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:04.982369Z",
     "start_time": "2020-03-09T07:33:04.978849Z"
    }
   },
   "outputs": [],
   "source": [
    "year_vars.remove('YrSold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:05.869066Z",
     "start_time": "2020-03-09T07:33:05.863050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
       "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n",
       "       'MoSold', 'SaleType', 'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# capture the column names for use later in the notebook\n",
    "final_columns = X_train.columns\n",
    "final_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:07.930697Z",
     "start_time": "2020-03-09T07:33:07.909638Z"
    }
   },
   "outputs": [],
   "source": [
    "# I will treat discrete variables as if they were categorical\n",
    "# to treat discrete as categorical using Feature-engine\n",
    "# we need to re-cast them as object\n",
    "\n",
    "X_train[discrete] = X_train[discrete].astype('O')\n",
    "X_test[discrete] = X_test[discrete].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:10.023580Z",
     "start_time": "2020-03-09T07:33:10.018569Z"
    }
   },
   "outputs": [],
   "source": [
    "# import relevant modules for feature engineering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine import missing_data_imputers as mdi\n",
    "from feature_engine import categorical_encoders as ce\n",
    "from feature_engine.variable_transformers import YeoJohnsonTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.discretisers import DecisionTreeDiscretiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:11.578215Z",
     "start_time": "2020-03-09T07:33:11.570194Z"
    }
   },
   "outputs": [],
   "source": [
    "house_preprocess = Pipeline([\n",
    "    \n",
    "    # missing data imputation \n",
    "    ('missing_ind', mdi.AddNaNBinaryImputer(\n",
    "        variables=['LotFrontage', 'MasVnrArea',  'GarageYrBlt'])),\n",
    "    ('imputer_num', mdi.MeanMedianImputer(imputation_method='mean',\n",
    "                                          variables=['LotFrontage', 'MasVnrArea',  'GarageYrBlt'])),\n",
    "    ('imputer_cat', mdi.CategoricalVariableImputer(variables=categorical)),\n",
    "\n",
    "    # categorical encoding \n",
    "     ('rare_label_enc', ce.RareLabelCategoricalEncoder(\n",
    "         tol=0.01,n_categories=6, variables=categorical+discrete)),\n",
    "    ('categorical_enc', ce.MeanCategoricalEncoder(variables = categorical + discrete)),\n",
    "     \n",
    "    # Transforming Numerical Variables\n",
    "    ('yjt', YeoJohnsonTransformer(variables = ['LotFrontage','MasVnrArea', 'GarageYrBlt'])),\n",
    "\n",
    "    \n",
    "    # discretisation and encoding\n",
    "    ('treeDisc',  DecisionTreeDiscretiser(cv=2, scoring='neg_mean_squared_error',\n",
    "                                   regression=True,\n",
    "                                   param_grid={'max_depth': [1,2,3,4,5,6]})),\n",
    "\n",
    "    # feature Scaling\n",
    "    ('scaler', StandardScaler()),\n",
    "    \n",
    "    \n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:18.934597Z",
     "start_time": "2020-03-09T07:33:15.096006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('missing_ind',\n",
       "                 AddNaNBinaryImputer(variables=['LotFrontage', 'MasVnrArea',\n",
       "                                                'GarageYrBlt'])),\n",
       "                ('imputer_num',\n",
       "                 MeanMedianImputer(imputation_method='mean',\n",
       "                                   variables=['LotFrontage', 'MasVnrArea',\n",
       "                                              'GarageYrBlt'])),\n",
       "                ('imputer_cat',\n",
       "                 CategoricalVariableImputer(variables=['MSZoning', 'Street',\n",
       "                                                       'Alley', 'LotShape',\n",
       "                                                       'LandContour',\n",
       "                                                       'Utilities', '...\n",
       "                                                    'Utilities', 'LotConfig',\n",
       "                                                    'LandSlope', 'Neighborhood',\n",
       "                                                    'Condition1', 'Condition2',\n",
       "                                                    'BldgType', 'HouseStyle',\n",
       "                                                    'OverallQual',\n",
       "                                                    'OverallCond', 'YearBuilt',\n",
       "                                                    'YearRemodAdd', 'RoofStyle',\n",
       "                                                    'RoofMatl', 'Exterior1st',\n",
       "                                                    'Exterior2nd', 'MasVnrType',\n",
       "                                                    'MasVnrArea', 'ExterQual',\n",
       "                                                    'ExterCond', 'Foundation',\n",
       "                                                    'BsmtQual', ...])),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_preprocess.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:21.351997Z",
     "start_time": "2020-03-09T07:33:20.885744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply Transformations\n",
    "X_train=house_preprocess.transform(X_train)\n",
    "X_test=house_preprocess.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span class=\"mark\">DO NOT CHANGE STEPS BEFORE THIS POINT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T04:00:12.095764Z",
     "start_time": "2020-03-09T04:00:12.093253Z"
    }
   },
   "source": [
    "## Regression Models- Tune different models one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:23.368390Z",
     "start_time": "2020-03-09T07:33:23.292686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: [ 8.68312903e-01 -6.26561684e+21  8.76203279e-01  8.98626806e-01\n",
      "  8.92290590e-01]\n",
      "CV score:  0.9114426745730106\n",
      "lr.coef_: [ 8.85927525e+02  9.63821950e+02  1.55093914e+03  2.38123720e+03\n",
      "  1.54867121e+03  3.94643841e+02  5.73339946e+02  1.32077662e+03\n",
      "  1.55946597e+03  2.25919167e+03  1.27504991e+03  1.12929618e+04\n",
      "  1.31777294e+03  2.04524613e+03  1.21008674e+03 -9.02846098e+02\n",
      "  1.58511847e+04 -9.82124059e+01 -5.41455300e+03  3.94119726e+03\n",
      "  3.73336495e+02 -1.17351708e+03  3.44591704e+03 -2.45906679e+03\n",
      " -8.92244713e+02  2.64169300e+02  2.55034152e+03  5.77675879e+02\n",
      "  1.02547905e+01  2.43524833e+03  5.95239944e+02  3.56353271e+03\n",
      "  1.33859388e+03  5.57728195e+03 -1.43383745e+03  2.11644961e+03\n",
      " -2.80153401e+02  7.89568089e+03  2.44320365e+02  1.63894561e+03\n",
      "  1.03758613e+03 -7.92545735e+02  1.21578274e+04  1.11657512e+04\n",
      "  4.20710717e+03  5.60685225e+03  2.72048329e+03 -1.21950180e+03\n",
      "  4.38283844e+03  5.39795630e+03  5.97516292e+02  2.94689148e+03\n",
      "  3.71875504e+03  3.03060751e+03  3.03991793e+03  6.48653394e+02\n",
      "  1.78422356e+03 -2.19543947e+03 -2.43854577e+03 -1.18750138e+03\n",
      "  4.31765061e+03  2.48635231e+02  2.50813698e+03  2.33631624e+02\n",
      "  7.36798066e+01  1.44837613e+03  1.54513968e+03 -1.69712829e+00\n",
      "  2.26100996e+03  2.67782301e+03 -1.45711262e+17  1.45711262e+17\n",
      " -3.01498819e+02 -2.05592005e+03  7.45807652e+02 -1.61204738e+02\n",
      " -1.31813584e+03  5.57575260e+03 -1.47800289e+02  2.60314741e+02\n",
      " -1.52950257e+02]\n",
      "lr.intercept_: 181040.6240487064\n",
      "Training score 0.9114426745730106\n",
      "LR Performance Test:  0.9114426745730106\n"
     ]
    }
   ],
   "source": [
    "# Train a linear regression model, report the coefficients and model performance \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(lr, X_train, y_train)\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"CV score: {}\".format((cv_scores)))\n",
    "print(\"CV score: \",lr.score(X_train, y_train))\n",
    "\n",
    "# Print Co-efficients\n",
    "print(\"lr.coef_:\", lr.coef_)\n",
    "print(\"lr.intercept_:\", lr.intercept_)\n",
    "\n",
    "# Check test data set performance\n",
    "\n",
    "X_train_preds = lr.predict(X_train)\n",
    "X_test_preds = lr.predict(X_test)\n",
    "\n",
    "print(\"Training score\",r2_score(y_train,X_train_preds))\n",
    "print(\"LR Performance Test: \", lr.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression with Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-efficients ['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_decision_function', '_estimator_type', '_get_param_names', '_get_tags', '_more_tags', '_preprocess_data', '_set_intercept', 'copy_X', 'fit', 'fit_intercept', 'get_params', 'n_jobs', 'normalize', 'predict', 'score', 'set_params']\n",
      "best params {'Poly__degree': 1}\n",
      "CV Score:  -2.168230286496948e+20\n",
      "CV Score:  0.9114985160662464\n",
      "train rmse 23507.198610424522\n",
      "train r2:  0.9114985160662464\n",
      "test rmse 29244.041532318097\n",
      "Test Score/r2:  0.8755530241459522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "reg_poly_pipe = Pipeline([\n",
    "    ('Poly',PolynomialFeatures()),\n",
    "    ('lreg',LinearRegression())\n",
    "])\n",
    "\n",
    "reg_poly_params = {'Poly__degree':range(1,2)}\n",
    "reg_poly_grid = GridSearchCV(reg_poly_pipe,reg_poly_params,cv=5, n_jobs=-1,return_train_score = True)\n",
    "\n",
    "reg_poly_grid.fit(X_train,y_train)\n",
    "\n",
    "X_train_preds = reg_poly_grid.predict(X_train)\n",
    "X_test_preds = reg_poly_grid.predict(X_test)\n",
    "\n",
    "print('Co-efficients',dir(reg_poly_pipe.named_steps['lreg']))\n",
    "#print('Intercept ',reg_poly_pipe.named_steps['lreg'].intercept_)\n",
    "print('best params',reg_poly_grid.best_params_)\n",
    "\n",
    "\n",
    "print('CV Score: ',reg_poly_grid.best_score_)\n",
    "#\n",
    "print('CV Score: ',reg_poly_grid.score(X_train,y_train))\n",
    "#Training score\n",
    "\n",
    "print('train rmse',sqrt(mean_squared_error(y_train,X_train_preds)))\n",
    "print(\"train r2: \", r2_score(y_train,X_train_preds))\n",
    "\n",
    "print('test rmse',sqrt(mean_squared_error(y_test,X_test_preds)))\n",
    "print(\"Test Score/r2: \", r2_score(y_test,X_test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are both CV Scores different ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 83216.40, NNZs: 81, Bias: 182.261203, T: 1051, Avg. loss: 579703583.510410\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 95552.30, NNZs: 81, Bias: -314.953744, T: 2102, Avg. loss: 363118011.566454\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 106476.63, NNZs: 81, Bias: -1845.385859, T: 3153, Avg. loss: 325498549.654393\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 110542.93, NNZs: 81, Bias: -2935.490991, T: 4204, Avg. loss: 314688786.263990\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 115241.45, NNZs: 81, Bias: -2407.238879, T: 5255, Avg. loss: 301906263.815102\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 122157.79, NNZs: 81, Bias: -3735.300981, T: 6306, Avg. loss: 297603804.171660\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 125669.81, NNZs: 81, Bias: -4476.929021, T: 7357, Avg. loss: 289648614.502727\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 128472.90, NNZs: 81, Bias: -4541.967265, T: 8408, Avg. loss: 288324972.510556\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 134083.28, NNZs: 81, Bias: -6329.423820, T: 9459, Avg. loss: 279094150.492774\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 132914.20, NNZs: 81, Bias: -5550.383363, T: 10510, Avg. loss: 243659882.490553\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133227.64, NNZs: 81, Bias: -5355.351323, T: 11561, Avg. loss: 236097277.852246\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 133482.11, NNZs: 81, Bias: -5330.128303, T: 12612, Avg. loss: 236231666.350848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 134067.95, NNZs: 81, Bias: -5612.812838, T: 13663, Avg. loss: 231929404.866714\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 134198.91, NNZs: 81, Bias: -5874.294141, T: 14714, Avg. loss: 235879862.312103\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 134525.42, NNZs: 81, Bias: -5707.288090, T: 15765, Avg. loss: 226324462.937745\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 134683.02, NNZs: 81, Bias: -5687.929218, T: 16816, Avg. loss: 225488921.482588\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 134714.05, NNZs: 81, Bias: -5755.758775, T: 17867, Avg. loss: 225483951.446905\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 134758.96, NNZs: 81, Bias: -5808.404925, T: 18918, Avg. loss: 225716931.574356\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 134954.52, NNZs: 81, Bias: -5767.864300, T: 19969, Avg. loss: 225756264.979127\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 135005.77, NNZs: 81, Bias: -5748.489351, T: 21020, Avg. loss: 223531150.273494\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 135019.04, NNZs: 81, Bias: -5755.662058, T: 22071, Avg. loss: 223623852.579512\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 135045.38, NNZs: 81, Bias: -5752.619527, T: 23122, Avg. loss: 223495062.291817\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 135028.76, NNZs: 81, Bias: -5779.200131, T: 24173, Avg. loss: 223560979.360754\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 135050.18, NNZs: 81, Bias: -5779.882864, T: 25224, Avg. loss: 223596902.554638\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 135052.77, NNZs: 81, Bias: -5781.334251, T: 26275, Avg. loss: 223056616.141042\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 135061.06, NNZs: 81, Bias: -5778.859324, T: 27326, Avg. loss: 223041264.138339\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 135063.60, NNZs: 81, Bias: -5780.342070, T: 28377, Avg. loss: 223048299.572201\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 135067.56, NNZs: 81, Bias: -5780.858165, T: 29428, Avg. loss: 223050100.847612\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 135069.08, NNZs: 81, Bias: -5783.108538, T: 30479, Avg. loss: 223040315.925915\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 135069.88, NNZs: 81, Bias: -5783.211206, T: 31530, Avg. loss: 222936866.842757\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 135070.88, NNZs: 81, Bias: -5783.165343, T: 32581, Avg. loss: 222935776.161672\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 135071.73, NNZs: 81, Bias: -5783.229818, T: 33632, Avg. loss: 222935593.902067\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 135072.52, NNZs: 81, Bias: -5783.332221, T: 34683, Avg. loss: 222935250.042430\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 135073.19, NNZs: 81, Bias: -5783.526759, T: 35734, Avg. loss: 222934172.224137\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 135073.35, NNZs: 81, Bias: -5783.542244, T: 36785, Avg. loss: 222912245.433325\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 135073.52, NNZs: 81, Bias: -5783.560183, T: 37836, Avg. loss: 222912143.750593\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 135073.67, NNZs: 81, Bias: -5783.581977, T: 38887, Avg. loss: 222912022.207238\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 135073.82, NNZs: 81, Bias: -5783.608750, T: 39938, Avg. loss: 222911841.697157\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 135073.98, NNZs: 81, Bias: -5783.631053, T: 40989, Avg. loss: 222911800.055550\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 39 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 90681.70, NNZs: 81, Bias: -183.122899, T: 840, Avg. loss: 747795425.002353\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 104591.55, NNZs: 81, Bias: -786.294549, T: 1680, Avg. loss: 418188826.978145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 114050.55, NNZs: 81, Bias: -1368.447179, T: 2520, Avg. loss: 366521380.283879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 121789.71, NNZs: 81, Bias: -1716.815293, T: 3360, Avg. loss: 322902666.476187\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 129535.57, NNZs: 81, Bias: -3277.143432, T: 4200, Avg. loss: 319282699.814875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 132483.73, NNZs: 81, Bias: -2545.579207, T: 5040, Avg. loss: 307630071.400723\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 140312.19, NNZs: 81, Bias: -3733.904505, T: 5880, Avg. loss: 295078527.157928\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 144037.15, NNZs: 81, Bias: -4309.107462, T: 6720, Avg. loss: 296115321.869371\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 144448.94, NNZs: 81, Bias: -4173.056589, T: 7560, Avg. loss: 239327152.728732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 145706.03, NNZs: 81, Bias: -4062.801758, T: 8400, Avg. loss: 234423369.102551\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 145231.66, NNZs: 81, Bias: -4386.411875, T: 9240, Avg. loss: 234964517.186649\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 146312.56, NNZs: 81, Bias: -4276.800556, T: 10080, Avg. loss: 238324470.559290\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 147711.21, NNZs: 81, Bias: -4057.030992, T: 10920, Avg. loss: 235055946.550932\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 147926.83, NNZs: 81, Bias: -4273.235715, T: 11760, Avg. loss: 231771844.426482\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 148533.39, NNZs: 81, Bias: -4315.197140, T: 12600, Avg. loss: 234257878.325560\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 149004.35, NNZs: 81, Bias: -4601.630414, T: 13440, Avg. loss: 235817522.243823\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 149691.15, NNZs: 81, Bias: -4708.038697, T: 14280, Avg. loss: 233210347.622146\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 150913.66, NNZs: 81, Bias: -4568.449205, T: 15120, Avg. loss: 230022249.226550\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 150698.76, NNZs: 81, Bias: -4780.086630, T: 15960, Avg. loss: 224222400.198185\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 150899.94, NNZs: 81, Bias: -4656.602322, T: 16800, Avg. loss: 223676952.438453\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 151017.71, NNZs: 81, Bias: -4638.345601, T: 17640, Avg. loss: 223111732.825230\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 150919.42, NNZs: 81, Bias: -4803.331958, T: 18480, Avg. loss: 222236468.547255\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 151157.44, NNZs: 81, Bias: -4706.730822, T: 19320, Avg. loss: 223953472.185928\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 151156.98, NNZs: 81, Bias: -4724.919831, T: 20160, Avg. loss: 221116581.549625\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 151195.79, NNZs: 81, Bias: -4713.295536, T: 21000, Avg. loss: 221364781.578802\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 151241.54, NNZs: 81, Bias: -4696.972600, T: 21840, Avg. loss: 221211538.041364\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 151235.42, NNZs: 81, Bias: -4720.394607, T: 22680, Avg. loss: 221100976.275196\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 151284.91, NNZs: 81, Bias: -4700.357421, T: 23520, Avg. loss: 221223021.916774\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 151289.31, NNZs: 81, Bias: -4700.775018, T: 24360, Avg. loss: 220683971.740165\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 151293.66, NNZs: 81, Bias: -4701.262688, T: 25200, Avg. loss: 220680609.185190\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 151298.30, NNZs: 81, Bias: -4701.530919, T: 26040, Avg. loss: 220671043.481089\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 151302.08, NNZs: 81, Bias: -4702.451071, T: 26880, Avg. loss: 220671912.638387\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 151308.21, NNZs: 81, Bias: -4701.499230, T: 27720, Avg. loss: 220655062.906557\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 151308.82, NNZs: 81, Bias: -4701.794976, T: 28560, Avg. loss: 220557234.183135\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 151309.42, NNZs: 81, Bias: -4702.096249, T: 29400, Avg. loss: 220555790.990469\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 151310.04, NNZs: 81, Bias: -4702.385334, T: 30240, Avg. loss: 220554555.483372\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 151310.70, NNZs: 81, Bias: -4702.639810, T: 31080, Avg. loss: 220553191.198759\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 151311.43, NNZs: 81, Bias: -4702.847232, T: 31920, Avg. loss: 220552140.393039\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 151311.57, NNZs: 81, Bias: -4702.892440, T: 32760, Avg. loss: 220529298.542078\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 151311.71, NNZs: 81, Bias: -4702.934876, T: 33600, Avg. loss: 220529081.173894\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 151311.86, NNZs: 81, Bias: -4702.978759, T: 34440, Avg. loss: 220528870.063019\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 151312.00, NNZs: 81, Bias: -4703.022491, T: 35280, Avg. loss: 220528647.387123\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 151312.14, NNZs: 81, Bias: -4703.065358, T: 36120, Avg. loss: 220528439.682230\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 43 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 88414.89, NNZs: 80, Bias: 947.955815, T: 840, Avg. loss: 666903868.904672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 102858.83, NNZs: 80, Bias: 2320.107359, T: 1680, Avg. loss: 384239452.769186\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 111071.13, NNZs: 80, Bias: 974.046321, T: 2520, Avg. loss: 326838637.733557\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 119042.41, NNZs: 80, Bias: 676.633547, T: 3360, Avg. loss: 308732759.322701\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 121925.19, NNZs: 80, Bias: 107.411360, T: 4200, Avg. loss: 300226310.079306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 129365.40, NNZs: 80, Bias: -1400.293335, T: 5040, Avg. loss: 283236548.954459\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 129069.84, NNZs: 80, Bias: -719.544670, T: 5880, Avg. loss: 237398340.575082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 128913.17, NNZs: 80, Bias: -935.931456, T: 6720, Avg. loss: 236825399.660416\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 129730.08, NNZs: 80, Bias: -847.775996, T: 7560, Avg. loss: 236740519.865582\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 130478.23, NNZs: 80, Bias: -859.289945, T: 8400, Avg. loss: 236857311.601807\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 131374.39, NNZs: 80, Bias: -826.792783, T: 9240, Avg. loss: 234675259.148903\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 131393.98, NNZs: 80, Bias: -931.178109, T: 10080, Avg. loss: 225900157.112337\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 131488.33, NNZs: 80, Bias: -978.184974, T: 10920, Avg. loss: 225116684.047723\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 131733.59, NNZs: 80, Bias: -925.384499, T: 11760, Avg. loss: 224116654.426560\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 131847.25, NNZs: 80, Bias: -945.312696, T: 12600, Avg. loss: 224531489.552628\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 132033.23, NNZs: 80, Bias: -914.687682, T: 13440, Avg. loss: 225085137.125642\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 132019.79, NNZs: 80, Bias: -945.514537, T: 14280, Avg. loss: 223003054.773892\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 132045.69, NNZs: 80, Bias: -949.055787, T: 15120, Avg. loss: 222784671.901829\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 132107.63, NNZs: 80, Bias: -926.857582, T: 15960, Avg. loss: 222719290.527254\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 132123.02, NNZs: 80, Bias: -937.661106, T: 16800, Avg. loss: 222841800.634504\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 132126.36, NNZs: 80, Bias: -956.562482, T: 17640, Avg. loss: 222852913.932294\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 132133.80, NNZs: 80, Bias: -955.578999, T: 18480, Avg. loss: 222341061.197298\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 132141.34, NNZs: 80, Bias: -954.522025, T: 19320, Avg. loss: 222328986.752908\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 132145.66, NNZs: 80, Bias: -955.666001, T: 20160, Avg. loss: 222321304.537521\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 132151.93, NNZs: 80, Bias: -955.509759, T: 21000, Avg. loss: 222319674.095600\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 132158.22, NNZs: 80, Bias: -955.322316, T: 21840, Avg. loss: 222313055.030972\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 132159.40, NNZs: 80, Bias: -955.332202, T: 22680, Avg. loss: 222205766.409316\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 132160.60, NNZs: 80, Bias: -955.340535, T: 23520, Avg. loss: 222204473.921831\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 132161.56, NNZs: 80, Bias: -955.505608, T: 24360, Avg. loss: 222201981.261006\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 132162.69, NNZs: 80, Bias: -955.563140, T: 25200, Avg. loss: 222201958.968727\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 132163.89, NNZs: 80, Bias: -955.561649, T: 26040, Avg. loss: 222200711.315642\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 132164.12, NNZs: 80, Bias: -955.568436, T: 26880, Avg. loss: 222178969.590332\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 132164.35, NNZs: 80, Bias: -955.579095, T: 27720, Avg. loss: 222178686.176368\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 132164.57, NNZs: 80, Bias: -955.595235, T: 28560, Avg. loss: 222178296.743036\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 132164.79, NNZs: 80, Bias: -955.604268, T: 29400, Avg. loss: 222178208.903179\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 132165.02, NNZs: 80, Bias: -955.614371, T: 30240, Avg. loss: 222177943.357061\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 36 epochs took 0.06 seconds\n",
      "-- Epoch 1\n",
      "Norm: 80556.78, NNZs: 81, Bias: 993.452138, T: 840, Avg. loss: 768099061.571840\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 109921.22, NNZs: 81, Bias: 1413.012271, T: 1680, Avg. loss: 414029506.566811\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 115293.20, NNZs: 81, Bias: 431.819143, T: 2520, Avg. loss: 348525667.885089\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 122992.76, NNZs: 81, Bias: 251.682332, T: 3360, Avg. loss: 323107690.867565\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 131892.95, NNZs: 81, Bias: -812.391055, T: 4200, Avg. loss: 308075426.058856\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 134720.20, NNZs: 81, Bias: -687.529713, T: 5040, Avg. loss: 298636937.312840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 135711.83, NNZs: 81, Bias: -1006.677793, T: 5880, Avg. loss: 245648428.171143\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 136963.45, NNZs: 81, Bias: -997.718423, T: 6720, Avg. loss: 242770839.217916\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 137731.40, NNZs: 81, Bias: -953.790555, T: 7560, Avg. loss: 240966891.717818\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 138214.81, NNZs: 81, Bias: -1315.839245, T: 8400, Avg. loss: 237735676.613716\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 139390.51, NNZs: 81, Bias: -1244.934577, T: 9240, Avg. loss: 239524302.387030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 139888.71, NNZs: 81, Bias: -1052.228681, T: 10080, Avg. loss: 229009516.036054\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 140047.16, NNZs: 81, Bias: -1089.012744, T: 10920, Avg. loss: 227745171.073587\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 140265.77, NNZs: 81, Bias: -1089.321327, T: 11760, Avg. loss: 227521856.813377\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 140579.08, NNZs: 81, Bias: -992.740386, T: 12600, Avg. loss: 226110411.481721\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 140894.58, NNZs: 81, Bias: -932.462603, T: 13440, Avg. loss: 224990151.451007\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 140682.65, NNZs: 81, Bias: -1117.393060, T: 14280, Avg. loss: 229127996.217701\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 140616.59, NNZs: 81, Bias: -1193.185989, T: 15120, Avg. loss: 224278686.507023\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 140655.66, NNZs: 81, Bias: -1191.782340, T: 15960, Avg. loss: 224848152.686549\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 140725.72, NNZs: 81, Bias: -1167.275108, T: 16800, Avg. loss: 224762340.833215\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 140782.74, NNZs: 81, Bias: -1152.820724, T: 17640, Avg. loss: 224677506.999042\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 140784.69, NNZs: 81, Bias: -1156.998525, T: 18480, Avg. loss: 224265073.033260\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 140787.65, NNZs: 81, Bias: -1160.449360, T: 19320, Avg. loss: 224235798.596246\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 140789.39, NNZs: 81, Bias: -1164.760961, T: 20160, Avg. loss: 224211903.259156\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 140793.96, NNZs: 81, Bias: -1166.955570, T: 21000, Avg. loss: 224195840.581979\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 140799.32, NNZs: 81, Bias: -1168.576910, T: 21840, Avg. loss: 224185309.557211\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 140800.48, NNZs: 81, Bias: -1168.833926, T: 22680, Avg. loss: 224064203.825475\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 140801.57, NNZs: 81, Bias: -1169.143215, T: 23520, Avg. loss: 224062580.775930\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 140802.69, NNZs: 81, Bias: -1169.432393, T: 24360, Avg. loss: 224060716.380670\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 140803.73, NNZs: 81, Bias: -1169.778554, T: 25200, Avg. loss: 224058404.417147\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 140804.85, NNZs: 81, Bias: -1170.061666, T: 26040, Avg. loss: 224057013.735650\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 140805.08, NNZs: 81, Bias: -1170.111723, T: 26880, Avg. loss: 224032772.283049\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 140805.32, NNZs: 81, Bias: -1170.162660, T: 27720, Avg. loss: 224032433.112462\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 140805.55, NNZs: 81, Bias: -1170.214485, T: 28560, Avg. loss: 224032083.648020\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 140805.78, NNZs: 81, Bias: -1170.264554, T: 29400, Avg. loss: 224031747.596993\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 140806.02, NNZs: 81, Bias: -1170.313065, T: 30240, Avg. loss: 224031402.474248\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 36 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 85334.35, NNZs: 81, Bias: -132.752134, T: 840, Avg. loss: 745900700.794601\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 102410.55, NNZs: 81, Bias: -1543.575215, T: 1680, Avg. loss: 442804084.967747\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 107195.78, NNZs: 81, Bias: -1185.768001, T: 2520, Avg. loss: 395459125.148405\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 109965.93, NNZs: 81, Bias: -3883.347262, T: 3360, Avg. loss: 376908868.485438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 122905.55, NNZs: 81, Bias: -5107.627959, T: 4200, Avg. loss: 355115416.088221\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 125726.26, NNZs: 81, Bias: -5552.321846, T: 5040, Avg. loss: 357597032.774524\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 129105.19, NNZs: 81, Bias: -6807.242857, T: 5880, Avg. loss: 353789578.591650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 132260.86, NNZs: 81, Bias: -7644.390360, T: 6720, Avg. loss: 341550670.191630\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 135581.81, NNZs: 81, Bias: -8382.789687, T: 7560, Avg. loss: 335147285.794299\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 137745.04, NNZs: 81, Bias: -8904.847357, T: 8400, Avg. loss: 324178835.635093\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 138745.42, NNZs: 81, Bias: -9392.388556, T: 9240, Avg. loss: 271989479.773768\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 139440.60, NNZs: 81, Bias: -9758.815745, T: 10080, Avg. loss: 269607167.029954\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 139552.30, NNZs: 81, Bias: -9950.376997, T: 10920, Avg. loss: 269243083.716755\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 141154.24, NNZs: 81, Bias: -9745.408973, T: 11760, Avg. loss: 269439229.431235\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 141160.47, NNZs: 81, Bias: -10124.993678, T: 12600, Avg. loss: 270070157.830090\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 141037.65, NNZs: 81, Bias: -10216.846118, T: 13440, Avg. loss: 259736943.237159\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 141211.52, NNZs: 81, Bias: -10130.184576, T: 14280, Avg. loss: 258285657.097013\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 140978.92, NNZs: 81, Bias: -10345.614175, T: 15120, Avg. loss: 258465143.978435\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 141180.57, NNZs: 81, Bias: -10250.465128, T: 15960, Avg. loss: 258732299.084345\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 141151.35, NNZs: 81, Bias: -10322.532439, T: 16800, Avg. loss: 258402983.837855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 141191.34, NNZs: 81, Bias: -10304.654881, T: 17640, Avg. loss: 256048542.061924\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 141125.34, NNZs: 81, Bias: -10361.099784, T: 18480, Avg. loss: 255322287.810130\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 141185.03, NNZs: 81, Bias: -10329.890593, T: 19320, Avg. loss: 256290689.536276\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 141183.18, NNZs: 81, Bias: -10342.951206, T: 20160, Avg. loss: 256047544.662882\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 141178.06, NNZs: 81, Bias: -10358.762700, T: 21000, Avg. loss: 255901022.217215\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 141192.82, NNZs: 81, Bias: -10350.649572, T: 21840, Avg. loss: 255574658.100427\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 141202.71, NNZs: 81, Bias: -10346.040237, T: 22680, Avg. loss: 255486779.242225\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 141208.34, NNZs: 81, Bias: -10344.462463, T: 23520, Avg. loss: 255440824.467950\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 141214.67, NNZs: 81, Bias: -10342.410636, T: 24360, Avg. loss: 255430617.816022\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 141219.41, NNZs: 81, Bias: -10341.503920, T: 25200, Avg. loss: 255416545.060475\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 141220.25, NNZs: 81, Bias: -10341.400208, T: 26040, Avg. loss: 255275907.264376\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 141221.02, NNZs: 81, Bias: -10341.342479, T: 26880, Avg. loss: 255274512.979588\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 141221.91, NNZs: 81, Bias: -10341.204651, T: 27720, Avg. loss: 255272877.499552\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 141222.58, NNZs: 81, Bias: -10341.223999, T: 28560, Avg. loss: 255271663.001927\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 141223.39, NNZs: 81, Bias: -10341.144167, T: 29400, Avg. loss: 255270507.900723\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 141223.53, NNZs: 81, Bias: -10341.143806, T: 30240, Avg. loss: 255242597.734554\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 141223.68, NNZs: 81, Bias: -10341.140035, T: 31080, Avg. loss: 255242417.688167\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 141223.82, NNZs: 81, Bias: -10341.140163, T: 31920, Avg. loss: 255242178.734561\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 141223.96, NNZs: 81, Bias: -10341.137560, T: 32760, Avg. loss: 255241996.599865\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 141224.10, NNZs: 81, Bias: -10341.138313, T: 33600, Avg. loss: 255241763.724476\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 40 epochs took 0.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 83668.70, NNZs: 81, Bias: 1629.312266, T: 841, Avg. loss: 728458930.157757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 100302.00, NNZs: 81, Bias: 620.374250, T: 1682, Avg. loss: 459130912.704224\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 110047.64, NNZs: 81, Bias: -425.254920, T: 2523, Avg. loss: 406265084.765981\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 118527.82, NNZs: 81, Bias: -1325.121024, T: 3364, Avg. loss: 380043147.907556\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 128588.59, NNZs: 81, Bias: -2681.054620, T: 4205, Avg. loss: 366175580.086859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 133397.54, NNZs: 81, Bias: -2645.791122, T: 5046, Avg. loss: 339471617.980582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 135859.49, NNZs: 81, Bias: -4713.403343, T: 5887, Avg. loss: 330224500.149571\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 141205.89, NNZs: 81, Bias: -4890.803209, T: 6728, Avg. loss: 328335381.607539\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 144304.74, NNZs: 81, Bias: -5100.411981, T: 7569, Avg. loss: 323965751.895774\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 146691.36, NNZs: 81, Bias: -6096.515641, T: 8410, Avg. loss: 316525949.416690\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 152682.56, NNZs: 81, Bias: -6684.384178, T: 9251, Avg. loss: 315129640.444993\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 156518.02, NNZs: 81, Bias: -7143.897704, T: 10092, Avg. loss: 311295304.323831\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 156908.85, NNZs: 81, Bias: -7174.335508, T: 10933, Avg. loss: 256666837.385584\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 157575.15, NNZs: 81, Bias: -7026.589017, T: 11774, Avg. loss: 256038133.209809\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 157815.24, NNZs: 81, Bias: -7311.442482, T: 12615, Avg. loss: 254790407.846381\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 158558.98, NNZs: 81, Bias: -7263.368130, T: 13456, Avg. loss: 250796514.255845\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 158349.51, NNZs: 81, Bias: -7855.183503, T: 14297, Avg. loss: 255121737.075654\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 158794.64, NNZs: 81, Bias: -7552.461563, T: 15138, Avg. loss: 245440483.317076\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 158850.85, NNZs: 81, Bias: -7606.281392, T: 15979, Avg. loss: 243673819.584417\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 158862.93, NNZs: 81, Bias: -7678.248708, T: 16820, Avg. loss: 242795564.917065\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 158999.60, NNZs: 81, Bias: -7627.773095, T: 17661, Avg. loss: 242934901.045218\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 159274.17, NNZs: 81, Bias: -7521.822980, T: 18502, Avg. loss: 242371662.028991\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 159132.64, NNZs: 81, Bias: -7651.535914, T: 19343, Avg. loss: 242448007.751082\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 159092.49, NNZs: 81, Bias: -7701.177955, T: 20184, Avg. loss: 240791965.711712\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 159161.38, NNZs: 81, Bias: -7663.571879, T: 21025, Avg. loss: 241463624.883236\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 159200.49, NNZs: 81, Bias: -7650.476130, T: 21866, Avg. loss: 241218408.280590\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 159186.50, NNZs: 81, Bias: -7679.512047, T: 22707, Avg. loss: 241311180.143939\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 159189.43, NNZs: 81, Bias: -7680.662046, T: 23548, Avg. loss: 240747304.007023\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 159194.09, NNZs: 81, Bias: -7680.475920, T: 24389, Avg. loss: 240762078.445755\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 159199.51, NNZs: 81, Bias: -7679.655267, T: 25230, Avg. loss: 240760616.075494\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 159203.90, NNZs: 81, Bias: -7679.703139, T: 26071, Avg. loss: 240750473.156865\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 159207.11, NNZs: 81, Bias: -7680.699130, T: 26912, Avg. loss: 240741540.326732\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 159208.23, NNZs: 81, Bias: -7680.517505, T: 27753, Avg. loss: 240627174.631506\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 159209.27, NNZs: 81, Bias: -7680.401738, T: 28594, Avg. loss: 240625523.840809\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 159210.38, NNZs: 81, Bias: -7680.221885, T: 29435, Avg. loss: 240623812.058612\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 159211.41, NNZs: 81, Bias: -7680.112510, T: 30276, Avg. loss: 240623017.630445\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 159212.31, NNZs: 81, Bias: -7680.107915, T: 31117, Avg. loss: 240621786.928265\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 159212.50, NNZs: 81, Bias: -7680.095920, T: 31958, Avg. loss: 240596920.717612\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 159212.69, NNZs: 81, Bias: -7680.085851, T: 32799, Avg. loss: 240596708.748711\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 159212.88, NNZs: 81, Bias: -7680.075888, T: 33640, Avg. loss: 240596494.042712\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 159213.07, NNZs: 81, Bias: -7680.068054, T: 34481, Avg. loss: 240596283.732961\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 159213.26, NNZs: 81, Bias: -7680.061748, T: 35322, Avg. loss: 240596073.080795\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 42 epochs took 0.05 seconds\n",
      "Cross-validation scores: [0.85629649 0.85130738 0.89215648 0.87668958 0.90063551]\n",
      "CV Score 0.891594730863832\n",
      "Mean CV Score : 0.880125237950295\n",
      "train rmse 26016.615364442063\n",
      "train r2:  0.891594730863832\n",
      "test rmse 34095.703270003876\n",
      "test r2:  0.8308356404127091\n",
      "best partams {'sgd_reg__alpha': 0.0005, 'sgd_reg__l1_ratio': 0.5, 'sgd_reg__learning_rate': 'adaptive', 'sgd_reg__penalty': 'elasticnet', 'sgd_reg__tol': 0.001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntrain rmse 24427.684457242212\\ntrain r2:  0.904431800897606\\ntest rmse 30888.23776210912\\ntest r2:  0.8611660031516002\\nbest partams {'sgd_reg__alpha': 0.001, 'sgd_reg__l1_ratio': 0.15, 'sgd_reg__learning_rate': 'adaptive', 'sgd_reg__penalty': 'elasticnet', 'sgd_reg__tol': 1e-06}\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "reg_sgd_pipe = Pipeline([\n",
    "    ('scaler',MinMaxScaler()),\n",
    "    ('sgd_reg',SGDRegressor(max_iter=1000,verbose=11,early_stopping=True,validation_fraction=0.2))\n",
    "])\n",
    "\n",
    "param_sgd = {'sgd_reg__learning_rate':['invscaling','adaptive'],\n",
    "            'sgd_reg__penalty':['l2', 'l1', 'elasticnet'],\n",
    "             'sgd_reg__alpha':[0.0001,0.0005,0.001],\n",
    "             'sgd_reg__l1_ratio':[0.15,0.20,0.40,0.50,0.60],\n",
    "             'sgd_reg__tol':[1e-4,1e-3]\n",
    "            }\n",
    "grid_sgd = GridSearchCV(reg_sgd_pipe,param_sgd,cv=5,n_jobs=-1,return_train_score=True)\n",
    "\n",
    "grid_sgd.fit(X_train,y_train)\n",
    "\n",
    "X_train_preds = grid_sgd.predict(X_train)\n",
    "X_test_preds = grid_sgd.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(grid_sgd, X_train, y_train)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "\n",
    "print(\"CV Score\",grid_sgd.score(X_train, y_train)) # Training score\n",
    "print(\"Mean CV Score :\",grid_sgd.best_score_) # CV Score\n",
    "\n",
    "\n",
    "print('train rmse',sqrt(mean_squared_error(y_train,X_train_preds)))\n",
    "print(\"train r2: \", r2_score(y_train,X_train_preds))\n",
    "\n",
    "print('test rmse',sqrt(mean_squared_error(y_test,X_test_preds)))\n",
    "print(\"test r2: \", r2_score(y_test,X_test_preds))\n",
    "\n",
    "print('best partams', grid_sgd.best_params_)\n",
    "\n",
    "\n",
    "'''\n",
    "Cross-validation scores: [0.85629649 0.85130738 0.89215648 0.87668958 0.90063551]\n",
    "CV Score 0.891594730863832\n",
    "Mean CV Score : 0.880125237950295\n",
    "train rmse 26016.615364442063\n",
    "train r2:  0.891594730863832\n",
    "test rmse 34095.703270003876\n",
    "test r2:  0.8308356404127091\n",
    "best partams {'sgd_reg__alpha': 0.0005, 'sgd_reg__l1_ratio': 0.5, 'sgd_reg__learning_rate': 'adaptive', 'sgd_reg__penalty': 'elasticnet', 'sgd_reg__tol': 0.001}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are CV scores different because they choose different train test sets ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:32.923175Z",
     "start_time": "2020-03-09T07:33:32.720114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.88\n",
      "\n",
      "Ridge parameters:  {'alpha': 100}\n",
      "Ridge.coef_: [ 6.21659729e+02  1.17460178e+03  1.42941553e+03  2.64606835e+03\n",
      "  1.51146267e+03  2.62791603e+02  6.67979067e+02  1.18774714e+03\n",
      "  1.42260925e+03  2.24214684e+03  1.25368077e+03  9.92739531e+03\n",
      "  1.23361742e+03  1.99010230e+03  1.20327177e+03 -6.63081364e+02\n",
      "  1.30900812e+04 -4.66276510e+02 -2.83583594e+03  3.23156417e+03\n",
      "  6.84148916e+02 -6.10003713e+02  1.78250368e+03 -1.24106895e+03\n",
      " -8.16647095e+02  8.17430994e+02  3.38262729e+03  6.89414122e+02\n",
      " -2.93079656e+02  2.71590898e+03  4.54540556e+02  3.45654634e+03\n",
      "  1.37124639e+03  5.85727188e+03 -1.21460614e+03  1.83762570e+03\n",
      " -2.50335442e+02  7.78490680e+03  1.59374113e+02  1.42274787e+03\n",
      "  1.23479897e+03 -5.43667577e+02  1.07696364e+04  1.01767254e+04\n",
      "  3.73457884e+03  6.25609926e+03  2.54341163e+03 -1.10107201e+03\n",
      "  3.81888633e+03  4.50746959e+03  8.23531957e+02  2.86618489e+03\n",
      "  4.19642055e+03  3.72923474e+03  2.86150257e+03  1.16162981e+03\n",
      "  1.86272306e+03 -1.46071138e+03 -1.49365951e+03 -7.89046316e+02\n",
      "  3.51419158e+03  1.50381127e+03  1.65614085e+03  5.11566556e+02\n",
      "  3.73952853e+01  1.30344611e+03  1.57916552e+03 -7.37193962e+01\n",
      "  2.06813040e+03  2.51850021e+03 -6.51713348e+02 -6.51713348e+02\n",
      " -3.70908918e+02 -1.54128339e+03  5.01320874e+02 -1.07090034e+02\n",
      "  2.35733301e+02  3.40278384e+03 -2.52546414e+02  3.26175004e+02\n",
      "  4.31488588e+00]\n",
      "Ridge.intercept_: 181040.6240487064\n",
      "Ridge Test Performance:  0.8731529205790173\n"
     ]
    }
   ],
   "source": [
    "# Train a Ridge regression model, report the coefficients, the best parameters, and model performance \n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "\n",
    "#define a list of parameters\n",
    "param_ridge = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100] }\n",
    "\n",
    "grid_ridge = GridSearchCV(ridge, param_ridge, cv=5, return_train_score = True)\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(grid_ridge.best_score_))\n",
    "\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('Ridge parameters: ', grid_ridge.best_params_)\n",
    "\n",
    "# print co-eff\n",
    "\n",
    "print(\"Ridge.coef_:\", grid_ridge.best_estimator_.coef_)\n",
    "print(\"Ridge.intercept_:\", grid_ridge.best_estimator_.intercept_)\n",
    "\n",
    "# Check test data set performance\n",
    "\n",
    "print(\"Ridge Test Performance: \", grid_ridge.score(X_test,y_test))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params  {'ridge_reg__alpha': 100}\n",
      "Cross-validation scores: [0.87180427 0.87337498 0.88443778 0.89665756 0.89454761]\n",
      "Cv score  0.8841976405377137\n",
      "train rmse 23661.930837005166\n",
      "train r2:  0.9103295889443214\n",
      "test rmse 29524.697349097773\n",
      "test r2:  0.8731529205790174\n",
      "Ridge Test Performance:  0.8731529205790174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ridge_pipe = Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('ridge_reg',Ridge())])\n",
    "\n",
    "ridge_params = {'ridge_reg__alpha':[0.001, 0.01,0.05, 0.1, 0.25,0.5,1, 10,100,150]}\n",
    "\n",
    "grid_ridge = GridSearchCV(ridge_pipe,ridge_params,cv=5,return_train_score = True)\n",
    "\n",
    "grid_ridge.fit(X_train,y_train)\n",
    "\n",
    "X_train_preds = grid_ridge.predict(X_train)\n",
    "X_test_preds = grid_ridge.predict(X_test)\n",
    "\n",
    "\n",
    "print('best params ',grid_ridge.best_params_)\n",
    "scores = cross_val_score(grid_ridge, X_train, y_train)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print('Cv score ',grid_ridge.best_score_)\n",
    "\n",
    "print('train rmse',sqrt(mean_squared_error(y_train,X_train_preds)))\n",
    "print(\"train r2: \", r2_score(y_train,X_train_preds))\n",
    "\n",
    "print('test rmse',sqrt(mean_squared_error(y_test,X_test_preds)))\n",
    "print(\"test r2: \", r2_score(y_test,X_test_preds))\n",
    "print(\"Ridge Test Performance: \", grid_ridge.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "'__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', \n",
    "'__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__',\n",
    "'__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__',\n",
    "'__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_is_fitted', \n",
    "'_estimator_type', '_format_results', '_get_param_names', '_get_tags', '_more_tags', '_pairwise',\n",
    "'_required_parameters', '_run_search', 'best_estimator_', 'best_index_', 'best_params_', 'best_score_', \n",
    "'classes_', 'cv', 'cv_results_', 'decision_function', 'error_score', 'estimator', 'fit', 'get_params', 'iid', \n",
    "'inverse_transform', 'multimetric_', 'n_jobs', 'n_splits_', 'param_grid', 'pre_dispatch', 'predict', \n",
    "'predict_log_proba', 'predict_proba', 'refit', 'refit_time_', 'return_train_score', 'score', 'scorer_', \n",
    "'scoring', 'set_params', 'transform', 'verbose\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:38.130469Z",
     "start_time": "2020-03-09T07:33:37.468173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.88\n",
      "\n",
      "Lasso parameters:  {'alpha': 100}\n",
      "Lasso.coef_: [ 5.98354347e+02  9.93527379e+02  1.31248909e+03  2.45908267e+03\n",
      "  1.47831122e+03  2.01697431e+02  4.99595526e+02  1.10518248e+03\n",
      "  1.37589148e+03  2.21586305e+03  1.19134068e+03  1.12945939e+04\n",
      "  1.13951391e+03  2.01113271e+03  1.11030992e+03 -7.18291866e+02\n",
      "  1.58637889e+04 -2.48057120e+02 -4.75773676e+03  3.55362072e+03\n",
      "  3.04826646e+02 -7.97883492e+02  1.41798949e+03 -5.97053298e+02\n",
      " -5.00534949e+02  0.00000000e+00  2.49235770e+03  6.28690101e+02\n",
      " -0.00000000e+00  2.12280516e+03  3.56997127e+02  3.48335820e+03\n",
      "  1.03573161e+03  5.80099431e+03 -1.22600059e+03  1.78568161e+03\n",
      " -1.93900166e+02  7.72000354e+03  1.02765199e+02  1.33679852e+03\n",
      "  1.22458458e+03 -4.25128495e+02  1.23009952e+04  1.13683366e+04\n",
      "  3.99723644e+03  5.84723766e+03  2.84083895e+03 -1.19002753e+03\n",
      "  3.90739089e+03  5.07525348e+03  5.97604436e+02  2.93758134e+03\n",
      "  3.76509853e+03  3.03646690e+03  2.87199457e+03  8.70912692e+02\n",
      "  1.35827672e+03 -1.63634329e+03 -1.60731811e+03 -7.16012142e+02\n",
      "  3.85437445e+03  4.69003975e+02  2.13068656e+03  4.15915245e+01\n",
      "  0.00000000e+00  1.27495552e+03  1.39525710e+03  0.00000000e+00\n",
      "  2.25974843e+03  2.59318123e+03 -1.16434500e+03 -2.21490338e-13\n",
      " -1.97952878e+02 -1.71216733e+03  4.54375406e+02 -6.31134282e+01\n",
      " -0.00000000e+00  4.10069748e+03 -0.00000000e+00  1.02306492e+02\n",
      "  0.00000000e+00]\n",
      "Lasso.intercept_: 181040.6240487064\n",
      "Lasso Test Performance:  0.877253397774493\n"
     ]
    }
   ],
   "source": [
    "# Train a Lasso regression model, report the coefficients, the best parameters, and model performance \n",
    "\n",
    "# YOUR CODE HERE\n",
    "'''\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(random_state=0)\n",
    "\n",
    "#define a list of parameters\n",
    "param_lasso = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100] }\n",
    "\n",
    "grid_lasso = GridSearchCV(lasso, param_lasso, cv=5, return_train_score = True)\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(grid_lasso.best_score_))\n",
    "print()\n",
    "\n",
    "#find best parameters\n",
    "print('Lasso parameters: ', grid_lasso.best_params_)\n",
    "\n",
    "# print co-eff\n",
    "\n",
    "print(\"Lasso.coef_:\", grid_lasso.best_estimator_.coef_)\n",
    "print(\"Lasso.intercept_:\", grid_lasso.best_estimator_.intercept_)\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Lasso Test Performance: \", grid_lasso.score(X_test,y_test))\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score 0.88562191775202\n",
      "Train RMSE 23569.530430171562\n",
      "Test RMSE 28943.028567200254\n",
      "Test Score/R-Square 0.8781017390279917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso = Lasso(selection='random',max_iter=10000)\n",
    "\n",
    "param_lasso = {'alpha':[0.001, 0.01,0.05, 0.1, 0.25,0.5,1, 10,100,150]}\n",
    "\n",
    "grid_lasso = GridSearchCV(lasso,param_lasso,cv=10, return_train_score = True)\n",
    "\n",
    "grid_lasso.fit(X_train,y_train)\n",
    "\n",
    "X_train_preds = grid_lasso.predict(X_train)\n",
    "X_test_preds = grid_lasso.predict(X_test)\n",
    "\n",
    "print('CV Score',grid_lasso.best_score_)\n",
    "print('Train RMSE',sqrt(mean_squared_error(y_train,X_train_preds)))\n",
    "print('Test RMSE',sqrt(mean_squared_error(y_test,X_test_preds)))\n",
    "print('Test Score/R-Square',grid_lasso.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regressor Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score  0.8354252209693938\n",
      "Best Params  {'knn_reg__leaf_size': 5, 'knn_reg__n_neighbors': 5, 'knn_reg__p': 1, 'knn_reg__weights': 'distance'}\n",
      "train RMSE 165.80829186118498\n",
      "train R2/score 0.9999955968722103\n",
      "test RMSE 38002.05080871088\n",
      "test R2/score 0.7898527883440282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('knn_reg',KNeighborsRegressor(algorithm='auto'))\n",
    "])\n",
    "\n",
    "knn_params = {'knn_reg__weights':['uniform','distance'],\n",
    "             'knn_reg__leaf_size': [5,10,20,30],\n",
    "             'knn_reg__n_neighbors': [5,10,15],\n",
    "             'knn_reg__p':[1,2,3]}\n",
    "\n",
    "knn_reg_grid = GridSearchCV(knn_pipe,knn_params,cv=5,return_train_score = True)\n",
    "\n",
    "knn_reg_grid.fit(X_train,y_train)\n",
    "\n",
    "X_train_preds = knn_reg_grid.predict(X_train)\n",
    "X_test_preds = knn_reg_grid.predict(X_test)\n",
    "\n",
    "print(\"CV score \",knn_reg_grid.best_score_)\n",
    "print(\"Best Params \",knn_reg_grid.best_params_)\n",
    "\n",
    "print(\"train RMSE\",sqrt(mean_squared_error(y_train,X_train_preds)))\n",
    "print(\"train R2/score\",r2_score(y_train,X_train_preds))\n",
    "\n",
    "print(\"test RMSE\",sqrt(mean_squared_error(y_test,X_test_preds)))\n",
    "print(\"test R2/score\",r2_score(y_test,X_test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree Regressor code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score  0.7980363024025918\n",
      "Best Params  {'dtree_reg__criterion': 'mse', 'dtree_reg__max_depth': 30, 'dtree_reg__max_features': 'auto', 'dtree_reg__min_samples_leaf': 8, 'dtree_reg__min_samples_split': 12, 'dtree_reg__splitter': 'random'}\n",
      "train RMSE 27697.236187058385\n",
      "train R2/score 0.8771368435976774\n",
      "test RMSE 36759.216163106896\n",
      "test R2/score 0.8033735005070397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nCV score  0.7814859520165511\\nBest Params  {'dtree_reg__criterion': 'friedman_mse', 'dtree_reg__max_depth': 20, 'dtree_reg__max_features': 'auto', 'dtree_reg__min_samples_leaf': 2, 'dtree_reg__min_samples_split': 8, 'dtree_reg__splitter': 'random'}\\ntrain RMSE 16912.129029241747\\ntrain R2/score 0.9541915743480076\\ntest RMSE 35541.86940384073\\ntest R2/score 0.8161811279310636\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dreg_pipe = Pipeline([\n",
    "    ('dtree_reg',DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "dreg_params = {\n",
    "    'dtree_reg__criterion':['mse','friedman_mse','mae'],\n",
    "    'dtree_reg__splitter':['random','best'],\n",
    "    'dtree_reg__max_depth':[20,30],\n",
    "    'dtree_reg__min_samples_split':[4,8,12,16],\n",
    "    'dtree_reg__min_samples_leaf' :[2,4,8],\n",
    "    'dtree_reg__max_features':['auto','sqrt']\n",
    "}\n",
    "\n",
    "dtree_reg_grid = GridSearchCV(dreg_pipe,dreg_params,cv=5,return_train_score = True)\n",
    "\n",
    "dtree_reg_grid.fit(X_train,y_train)\n",
    "\n",
    "X_train_preds = dtree_reg_grid.predict(X_train)\n",
    "X_test_preds = dtree_reg_grid.predict(X_test)\n",
    "\n",
    "print(\"CV score \",dtree_reg_grid.best_score_)\n",
    "print(\"Best Params \",dtree_reg_grid.best_params_)\n",
    "\n",
    "print(\"train RMSE\",sqrt(mean_squared_error(y_train,X_train_preds)))\n",
    "print(\"train R2/score\",r2_score(y_train,X_train_preds))\n",
    "\n",
    "print(\"test RMSE\",sqrt(mean_squared_error(y_test,X_test_preds)))\n",
    "print(\"test R2/score\",r2_score(y_test,X_test_preds))\n",
    "\n",
    "'''\n",
    "CV score  0.7814859520165511\n",
    "Best Params  {'dtree_reg__criterion': 'friedman_mse', 'dtree_reg__max_depth': 20, 'dtree_reg__max_features': 'auto', 'dtree_reg__min_samples_leaf': 2, 'dtree_reg__min_samples_split': 8, 'dtree_reg__splitter': 'random'}\n",
    "train RMSE 16912.129029241747\n",
    "train R2/score 0.9541915743480076\n",
    "test RMSE 35541.86940384073\n",
    "test R2/score 0.8161811279310636\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score  0.9004499345276106\n",
      "Best Params  {'svm_reg__coef0': 10.0, 'svm_reg__degree': 5, 'svm_reg__gamma': 'auto', 'svm_reg__kernel': 'poly'}\n",
      "train RMSE 17044.420472834856\n",
      "train R2/score 0.9534721185647854\n",
      "test RMSE 29404.570032081163\n",
      "test R2/score 0.8741830276841772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg_pipe = Pipeline([\n",
    "    ('svm_reg',SVR())\n",
    "])\n",
    "\n",
    "svm_reg_params = {\n",
    "    'svm_reg__kernel':['linear','poly','rbf','sigmoid'],\n",
    "    'svm_reg__degree':[3,4,5],\n",
    "    'svm_reg__gamma': ['auto','scale'],\n",
    "    'svm_reg__coef0':[2.0,4.0,10.0,15.0]\n",
    "}\n",
    "\n",
    "svm_reg_grid = GridSearchCV(svm_reg_pipe,svm_reg_params,cv=5,return_train_score = True)\n",
    "\n",
    "svm_reg_grid.fit(X_train,y_train)\n",
    "\n",
    "X_train_preds = svm_reg_grid.predict(X_train)\n",
    "X_test_preds = svm_reg_grid.predict(X_test)\n",
    "\n",
    "print(\"CV score \",svm_reg_grid.best_score_)\n",
    "print(\"Best Params \",svm_reg_grid.best_params_)\n",
    "\n",
    "print(\"train RMSE\",sqrt(mean_squared_error(y_train,X_train_preds)))\n",
    "print(\"train R2/score\",r2_score(y_train,X_train_preds))\n",
    "\n",
    "print(\"test RMSE\",sqrt(mean_squared_error(y_test,X_test_preds)))\n",
    "print(\"test R2/score\",r2_score(y_test,X_test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T03:59:33.754940Z",
     "start_time": "2020-03-09T03:59:33.751933Z"
    }
   },
   "source": [
    "## Tune Multiple Models with one GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:43.119468Z",
     "start_time": "2020-03-09T07:33:43.115457Z"
    }
   },
   "outputs": [],
   "source": [
    "model_gs = Pipeline([(\"Poly\",PolynomialFeatures()),(\"regressor\", LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:44.906746Z",
     "start_time": "2020-03-09T07:33:44.900729Z"
    }
   },
   "outputs": [],
   "source": [
    "model_parm_gd = [\n",
    "    { 'regressor': [LinearRegression()]},\n",
    "    \n",
    "    { 'regressor': [Ridge()],\n",
    "      'regressor__alpha':[0.001, 0.01, 0.1, 1, 10, 100,200],\n",
    "    'regressor__solver':['auto']},\n",
    "    \n",
    "    { 'regressor': [Lasso()],\n",
    "      'regressor__alpha':[0.001, 0.01, 0.1, 1, 10, 100,200]},\n",
    " \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:46.478370Z",
     "start_time": "2020-03-09T07:33:46.475362Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_house_pipe = GridSearchCV(model_gs, model_parm_gd,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:48.862449Z",
     "start_time": "2020-03-09T07:33:47.915915Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2236734277.5811195, tolerance: 657118734.8147435\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2314463065.5480876, tolerance: 655974723.0327224\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2206285636.38415, tolerance: 635955900.9288123\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2290521048.545657, tolerance: 642749145.1567798\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2415103080.3513923, tolerance: 689033704.679551\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10735084585.176062, tolerance: 657118734.8147435\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10918738110.095474, tolerance: 655974723.0327224\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11865667864.470778, tolerance: 635955900.9288123\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12090478090.541023, tolerance: 642749145.1567798\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10703341660.377636, tolerance: 689033704.679551\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2647202394.4553223, tolerance: 657118734.8147435\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1494749218.5318146, tolerance: 655974723.0327224\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1058959564.560852, tolerance: 635955900.9288123\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1584225201.543045, tolerance: 642749145.1567798\n",
      "  positive)\n",
      "/opt/anaconda3/envs/buan6341/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6629443019.999504, tolerance: 689033704.679551\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('Poly',\n",
       "                                        PolynomialFeatures(degree=2,\n",
       "                                                           include_bias=True,\n",
       "                                                           interaction_only=False,\n",
       "                                                           order='C')),\n",
       "                                       ('regressor',\n",
       "                                        LinearRegression(copy_X=True,\n",
       "                                                         fit_intercept=True,\n",
       "                                                         n_jobs=None,\n",
       "                                                         normalize=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'regressor': [LinearRegression(copy_X=Tru...\n",
       "                          'regressor__solver': ['auto']},\n",
       "                         {'regressor': [Lasso(alpha=200, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=1000,\n",
       "                                              normalize=False, positive=False,\n",
       "                                              precompute=False,\n",
       "                                              random_state=None,\n",
       "                                              selection='cyclic', tol=0.0001,\n",
       "                                              warm_start=False)],\n",
       "                          'regressor__alpha': [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                               200]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_house_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:50.694053Z",
     "start_time": "2020-03-09T07:33:50.690545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor': Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001), 'regressor__alpha': 100}\n"
     ]
    }
   ],
   "source": [
    "#print(grid_search_house_pipe.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor': Lasso(alpha=200, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), 'regressor__alpha': 200}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_house_pipe.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:51.930133Z",
     "start_time": "2020-03-09T07:33:51.922105Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's get the predictions\n",
    "X_train_preds = grid_search_house_pipe.predict(X_train)\n",
    "X_test_preds = grid_search_house_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:54.122514Z",
     "start_time": "2020-03-09T07:33:54.118504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.88\n"
     ]
    }
   ],
   "source": [
    "#print(\"Best Mean Cross-validation score: {:.2f}\".format(grid_search_house_pipe.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.83\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Mean Cross-validation score: {:.2f}\".format(grid_search_house_pipe.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T07:33:56.073138Z",
     "start_time": "2020-03-09T07:33:56.060105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 559886970.9352162\n",
      "train rmse: 23661.93083700517\n",
      "train r2: 0.9103295889443213\n",
      "\n",
      "test mse: 871707753.5558217\n",
      "test rmse: 29524.697349097783\n",
      "test r2: 0.8731529205790173\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# check model performance:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('train mse: {}'.format(mean_squared_error(y_train, X_train_preds)))\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('train r2: {}'.format(r2_score(y_train, X_train_preds)))\n",
    "print()\n",
    "print('test mse: {}'.format(mean_squared_error(y_test, X_test_preds)))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n",
    "print('test r2: {}'.format(r2_score(y_test, X_test_preds)))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 112781889.48419684\n",
      "train rmse: 10619.881801799718\n",
      "train r2: 0.981937071382834\n",
      "\n",
      "test mse: 865352885.5659168\n",
      "test rmse: 29416.88096256836\n",
      "test r2: 0.8740776530267179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('train mse: {}'.format(mean_squared_error(y_train, X_train_preds)))\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('train r2: {}'.format(r2_score(y_train, X_train_preds)))\n",
    "print()\n",
    "print('test mse: {}'.format(mean_squared_error(y_test, X_test_preds)))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n",
    "print('test r2: {}'.format(r2_score(y_test, X_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "211.997px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
